{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chapter1 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding ground states\n",
    "\n",
    "Having found a way of encoding the states, the next step is to implement a way of finding the ground state. To this end, we consider a nearest-neighbour Hamiltonian H, of the form\n",
    "$$H = \\sum_n h_{n, n+1}.$$\n",
    "Here $h_{n,n+1}$ is a hermitian operator acting non-trivially on the sites $n$ and $n+1$. As in any variational approach, the variational principle serves as a guide for finding ground-state approximations, we want to minimise the expectation value of the energy,\n",
    "$$ \\min_A \\frac{<\\Psi(A)| H | \\Psi(A) >}{<\\Psi(A)|\\Psi(A)>}. $$\n",
    "\n",
    "In the thermodynamic limit the energy diverges with system size, but, since we are working with translation-invariant states only, we should rather minimise the energy density. We also will restrict to properly normalised states. Diagrammatically, the minimization problem is recast as\n",
    "\n",
    "![minDiagram](img/2minham.png)\n",
    "\n",
    "We now turn to some numerical optimization strategies for minimizing this energy density directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The gradient\n",
    "\n",
    "Any optimization problem relies on an efficient evaluation of the gradient, so the first thing to do is to compute this quantity (efficiently). The objective function $f$ that we want to minimize is a real function of the complex-valued $A$, or equivalently, the independent variables $A$ and $Abar$. The gradient $g$ is then obtained by differentiating $f(Abar,A)$ with respect to Abar,\n",
    "\n",
    "![gradCalc](img/gradientCalc.png)\n",
    "\n",
    "If we make sure that the MPS is properly normalised, and subtract the current energy density from every term in the hamiltonian, the gradient takes on the simple form\n",
    "$$ g = 2 \\partial_Abar <\\Psi(A)| h | \\Psi(A) >.$$\n",
    "It will prove useful to implement \n",
    "\n",
    "The gradient is obtained by differentiating the expression\n",
    "\n",
    "![grad2](img/grad2.png)\n",
    "\n",
    "with respect to $Abar$. Differentiating with respect to one $Abar$ tensor amounts to leaving out that tensor, and interpreting the open legs as outgoing ones, i.e. each term looks like\n",
    "\n",
    "![gradTerms](img/gradTerms.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reducedHamUniform(h, A, l=None, r=None):\n",
    "    \"\"\"\n",
    "    Renormalise Hamiltonian such that its expectation value is 0.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        h : np.array (d, d, d, d)\n",
    "            Hamiltonian that needs to be reduced,\n",
    "            ordered topLeft-topRight-bottomLeft-bottomRight.\n",
    "        A : np.array (D, d, D)\n",
    "            MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right.\n",
    "        l : np.array(D, D), optional\n",
    "            left fixed point of transfermatrix,\n",
    "            normalised.\n",
    "        r : np.array(D, D), optional\n",
    "            right fixed point of transfermatrix,\n",
    "            normalised.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        hTilde : np.array (d, d, d, d)\n",
    "            reduced Hamiltonian,\n",
    "            ordered topLeft-topRight-bottomLeft-bottomRight.\n",
    "    \"\"\"\n",
    "    \n",
    "    # calculate fixed points if not supplied\n",
    "    if l is None or r is None:\n",
    "        l, r = fixedPoints(A)\n",
    "    \n",
    "    # calculate expectation value\n",
    "    e = expVal2Uniform(h, A, l, r)\n",
    "    \n",
    "    # substract from hamiltonian\n",
    "    hTilde = h - e * ncon((np.eye(d), np.eye(d)), ([-1, -3], [-2, -4]))\n",
    "    \n",
    "    return hTilde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terms of the 'center' kind\n",
    "The first kind of terms that arise is are obtained by removing one of the $Abar$ on the legs of the Hamiltonian term. This leads to\n",
    "\n",
    "![gradTerms](img/centerTerms.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradCenterTerms(hTilde, A, l=None, r=None):\n",
    "    \"\"\"\n",
    "    Calculate the value of the center terms.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        hTilde : np.array (d, d, d, d)\n",
    "            reduced Hamiltonian,\n",
    "            ordered topLeft-topRight-bottomLeft-bottomRight.\n",
    "        A : np.array (D, d, D)\n",
    "            MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right.\n",
    "        l : np.array(D, D), optional\n",
    "            left fixed point of transfermatrix,\n",
    "            normalised.\n",
    "        r : np.array(D, D), optional\n",
    "            right fixed point of transfermatrix,\n",
    "            normalised.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        term1 : np.array(D, d, D)\n",
    "            first term of gradient,\n",
    "            ordered left-mid-right.\n",
    "        term2 : np.array(D, d, D)\n",
    "            second term of gradient,\n",
    "            ordered left-mid-right.\n",
    "    \"\"\"\n",
    "    \n",
    "    # calculate fixed points if not supplied\n",
    "    if l is None or r is None:\n",
    "        l, r = fixedPoints(A)\n",
    "    \n",
    "    # calculate first contraction\n",
    "    term1 = ncon((l, r, A, A, np.conj(A), hTilde), ([6, 1], [5, -3], [1, 3, 2], [2, 4, 5], [6, 7, -1], [3, 4, 7, -2]))\n",
    "    \n",
    "    # calculate second contraction\n",
    "    term2 = ncon((l, r, A, A, np.conj(A), hTilde), ([-1, 1], [5, 7], [1, 3, 2], [2, 4, 5], [-3, 6, 7], [3, 4, -2, 6]))\n",
    "    \n",
    "    return term1, term2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terms of the 'left' kind\n",
    "For the terms where we omit an $Abar$ tensor to the left of the operator $h$, we can contract everything to the left of this missing $Abar$ tensor to the fixed point $l$, and everything to the right of the site containing the Hamiltonian is $r$.\n",
    "\n",
    "In between these two parts of the network, there is $E^n$, the transfermatrix multiplied $n$ times where $n$ is the separation between the two regions. Thus, summing all terms of the 'left' kind together means that we sum over $n$, and the relevant tensor becomes\n",
    "\n",
    "$$Esum = 1 + E + E^2 + \\dots = \\frac{1}{1-E}.$$\n",
    "\n",
    "However, we must be careful when doing this, as the transfer matrix has leading eigenvalue 1, this quantity will diverge. This can be solved by defining a regularized transfer matrix $Etilde$, substracting the divergent part:\n",
    "\n",
    "![regTransfer](img/regTransfer.png)\n",
    "\n",
    "and only then taking the inverse. Note that this will not change the result, as we are working with a regularised hamiltonian such that the contributions we substracted would have evaluated to 0.\n",
    "\n",
    "$$ Esumtilde = \\frac{1}{1-Etilde} =: (1 - E)^p $$\n",
    "\n",
    "Using this, we define the partial contraction\n",
    "\n",
    "![Rh](img/Rh.png)\n",
    "\n",
    "such that the sum of all left terms equals\n",
    "\n",
    "![leftTerms](img/leftTerm.png)\n",
    "\n",
    "Concretely, implementing this inverse naively would be an ill-defined problem, so we resort to other algorithms to find $R_h$. Multiplying both sides with $(1-Etilde)$ results in an equation of the form $Ax = b$, which may be solved for $x$ by implementing a  Generalized Minimal RESidual (GMRES) algorithm. \n",
    "\n",
    "Note that such an algorithm requires only the action of A, not the actual matrix, such that its construction should again be implemented using a handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rh(hTilde, A, l=None, r=None):\n",
    "    \"\"\"\n",
    "    Find the partial contraction for Rh.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        hTilde : np.array (d, d, d, d)\n",
    "            reduced Hamiltonian,\n",
    "            ordered topLeft-topRight-bottomLeft-bottomRight,\n",
    "            renormalised.\n",
    "        A : np.array (D, d, D)\n",
    "            MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right.\n",
    "        l : np.array(D, D), optional\n",
    "            left fixed point of transfermatrix,\n",
    "            normalised.\n",
    "        r : np.array(D, D), optional\n",
    "            right fixed point of transfermatrix,\n",
    "            normalised.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Rh : np.array(D, D)\n",
    "            result of contraction,\n",
    "            ordered top-bottom.\n",
    "    \"\"\"\n",
    "    \n",
    "    D = A.shape[0]\n",
    "    \n",
    "    # if l, r not specified, find fixed points\n",
    "    if l is None or r is None:\n",
    "        l, r = fixedPoints(A)\n",
    "    \n",
    "    # construct regularised transferRight operator\n",
    "    def Etilde(v):\n",
    "        \"\"\"\n",
    "        Applies 1 - Etilde on a right vector.\n",
    "        \"\"\"\n",
    "        v.reshape(D, D)\n",
    "        \n",
    "        # transfermatrix contribution\n",
    "        transfer = ncon((A, np.conj(A), v), ([-1, 2, 1], [-2, 2, 3], [1, 3]))\n",
    "        \n",
    "        # fixed point contribution\n",
    "        fixed = np.trace(v @ l) * r\n",
    "        \n",
    "        Etilde = eye(D, D) - transfer + fixed\n",
    "        \n",
    "        return np.reshape(Etilde, (D ** 2))\n",
    "        \n",
    "       \n",
    "    \n",
    "    # construct b\n",
    "    b = ncon((r, A, A, np.conj(A), np.conj(A), hTilde), ([4, 5], [-1, 2, 1], [1, 3, 4], [-2, 8, 7], [7, 6, 5], [2, 3, 8, 6]))\n",
    "    \n",
    "    # solve Ax = b for x\n",
    "    A = LinearOperator((D ** 2, D ** 2), matvec=Etilde) \n",
    "    b.reshape(D ** 2)\n",
    "    Rh = gmres(A, b)[0]\n",
    "    \n",
    "    return Rh.reshape((D, D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradLeftTerms(hTilde, A, l=None, r=None):\n",
    "    \"\"\"\n",
    "    Calculate the value of the left terms.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        hTilde : np.array (d, d, d, d)\n",
    "            reduced Hamiltonian,\n",
    "            ordered topLeft-topRight-bottomLeft-bottomRight,\n",
    "            renormalised.\n",
    "        A : np.array (D, d, D)\n",
    "            MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right.\n",
    "        l : np.array(D, D), optional\n",
    "            left fixed point of transfermatrix,\n",
    "            normalised.\n",
    "        r : np.array(D, D), optional\n",
    "            right fixed point of transfermatrix,\n",
    "            normalised.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        leftTerms : np.array(D, d, D)\n",
    "            left terms of gradient,\n",
    "            ordered left-mid-right.\n",
    "    \"\"\"\n",
    "    \n",
    "    # if l, r not specified, find fixed points\n",
    "    if l is None or r is None:\n",
    "        l, r = fixedPoints(A)\n",
    "    \n",
    "    # calculate partial contraction\n",
    "    Rh = Rh(hTilde, A, l, r)\n",
    "    \n",
    "    # calculate full contraction\n",
    "    leftTerms = ncon((Rh, A, l), ([1, -3], [2, -2, 1], [-1, 2]))\n",
    "    \n",
    "    return leftTerms    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terms of the 'right' kind\n",
    "In a very similar way, the terms where we leave out an $Abar$ to the right of the operator $h$, can be evaluated with the following contractions:\n",
    "\n",
    "![Lh](img/Lh.png)\n",
    "\n",
    "such that the sum of all 'right' terms equals\n",
    "\n",
    "![rightTerms](img/rightTerm.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lh(hTilde, A, l=None, r=None):\n",
    "    \"\"\"\n",
    "    Find the partial contraction for Lh.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        hTilde : np.array (d, d, d, d)\n",
    "            reduced Hamiltonian,\n",
    "            ordered topLeft-topRight-bottomLeft-bottomRight,\n",
    "            renormalised.\n",
    "        A : np.array (D, d, D)\n",
    "            MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right.\n",
    "        l : np.array(D, D), optional\n",
    "            left fixed point of transfermatrix,\n",
    "            normalised.\n",
    "        r : np.array(D, D), optional\n",
    "            right fixed point of transfermatrix,\n",
    "            normalised.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Lh : np.array(D, D)\n",
    "            result of contraction,\n",
    "            ordered bottom-top.\n",
    "    \"\"\"\n",
    "    \n",
    "    D = A.shape[0]\n",
    "    \n",
    "    # if l, r not specified, find fixed points\n",
    "    if l is None or r is None:\n",
    "        l, r = fixedPoints(A)\n",
    "    \n",
    "    # construct regularised transferLeft operator\n",
    "    def Etilde(v):\n",
    "        \"\"\"\n",
    "        Applies 1 - Etilde on a left vector.\n",
    "        \"\"\"\n",
    "        v.reshape(D, D)\n",
    "        \n",
    "        # transfer matrix contribution\n",
    "        transfer = ncon((v, A, np.conj(A)), ([3, 1], [1, 2, -2], [3, 2, -1]))\n",
    "        \n",
    "        # fixed point contribution\n",
    "        fixed = np.trace(v @ r) * l\n",
    "        \n",
    "        Etilde = eye(D, D) - transfer + fixed\n",
    "        \n",
    "        return np.reshape(Etilde, (D ** 2))\n",
    "        \n",
    "    # construct b\n",
    "    b = ncon((l, A, A, np.conj(A), np.conj(A), hTilde), ([5, 1], [1, 3, 2], [2, 4, -2], [5, 6, 7], [7, 8, -1], [3, 4, 6, 8]))    \n",
    "    \n",
    "    # solve Ax = b for x\n",
    "    A = LinearOperator((D ** 2, D ** 2), matvec=Etilde) \n",
    "    b.reshape(D ** 2)\n",
    "    Lh = gmres(A, b)[0]\n",
    "    \n",
    "    return Lh.reshape((D, D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradRightTerms(hTilde, A, l=None, r=None):\n",
    "    \"\"\"\n",
    "    Calculate the value of the right terms.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        hTilde : np.array (d, d, d, d)\n",
    "            reduced Hamiltonian,\n",
    "            ordered topLeft-topRight-bottomLeft-bottomRight,\n",
    "            renormalised.\n",
    "        A : np.array (D, d, D)\n",
    "            MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right.\n",
    "        l : np.array(D, D), optional\n",
    "            left fixed point of transfermatrix,\n",
    "            normalised.\n",
    "        r : np.array(D, D), optional\n",
    "            right fixed point of transfermatrix,\n",
    "            normalised.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        rightTerms : np.array(D, d, D)\n",
    "            right terms of gradient,\n",
    "            ordered left-mid-right.\n",
    "    \"\"\"\n",
    "    \n",
    "    # if l, r not specified, find fixed points\n",
    "    if l is None or r is None:\n",
    "        l, r = fixedPoints(A)\n",
    "    \n",
    "    # calculate partial contraction\n",
    "    Lh = Lh(hTilde, A, l, r)\n",
    "    \n",
    "    # calculate full contraction\n",
    "    rightTerms = ncon((Lh, A, r), ([-1, 1], [1, -2, 2], [2, -3]))\n",
    "    \n",
    "    return rightTerms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summing up, the gradient is found by summing up everything:\n",
    "\n",
    "![gradient](img/gradient.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(h, A, l=None, r=None):\n",
    "    \"\"\"\n",
    "    Calculate the gradient of the expectation value of h @ MPS A.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        h : np.array (d, d, d, d)\n",
    "            Hamiltonian,\n",
    "            ordered topLeft-topRight-bottomLeft-bottomRight,\n",
    "            renormalised.\n",
    "        A : np.array (D, d, D)\n",
    "            MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right.\n",
    "        l : np.array(D, D), optional\n",
    "            left fixed point of transfermatrix,\n",
    "            normalised.\n",
    "        r : np.array(D, D), optional\n",
    "            right fixed point of transfermatrix,\n",
    "            normalised.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        grad : np.array(D, d, D)\n",
    "            Gradient,\n",
    "            ordered left-mid-right.\n",
    "    \"\"\"\n",
    "    \n",
    "    # if l, r not specified, find fixed points\n",
    "    if l is None or r is None:\n",
    "        l, r = fixedPoints(A)\n",
    "        \n",
    "    # renormalise Hamiltonian\n",
    "    hTilde = reducedHamUniform(h, A, l, r)\n",
    "        \n",
    "    # find terms\n",
    "    centerTerm1, centerTerm2 = gradCenterTerms(hTilde, A, l, r)\n",
    "    leftTerms = gradLeftTerms(hTilde, A, l, r)\n",
    "    rightTerms = gradRightTerms(hTilde, A, l, r)\n",
    "    \n",
    "    grad = 2 * np.sum(centerTerm1, centerTerm2, leftTerms, rightTerad)\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent algorithms\n",
    "The simplest way to use this information to find the ground state of a Hamiltonian is then to use a method of gradient descent, or just by iterating, for a small step $\\epsilon$:\n",
    "\n",
    "$$ A_{i+1} = A_i - \\epsilon g $$\n",
    "\n",
    "However, this can be further improved upon by using more advanced algorithms, as for example those already implemented by the scipy package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groundStateGradDescent(h, D, eps=1e-3, A0=None, rtol=1e-3):\n",
    "    \"\"\"\n",
    "    Find the ground state using gradient descent.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        h : np.array (d, d, d, d)\n",
    "            Hamiltonian to minimise,\n",
    "            ordered topLeft-topRight-bottomLeft-bottomRight.\n",
    "        D : int\n",
    "            Bond dimension\n",
    "        eps : float\n",
    "            Stepsize.\n",
    "        A0 : np.array (D, d, D)\n",
    "            MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right,\n",
    "            initial guess.\n",
    "        rtol : float\n",
    "            Relative convergence criterium.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        E : float\n",
    "            expectation value @ minimum\n",
    "        A : np.array(D, d, D)\n",
    "            ground state MPS,\n",
    "            ordered left-mid-right.\n",
    "    \"\"\"\n",
    "    \n",
    "    d = h.shape[0]\n",
    "    \n",
    "    # if no initial value, choose random\n",
    "    if A0 is None:\n",
    "        A0 = createMPS(D, d, D)\n",
    "    \n",
    "    # calculate gradient\n",
    "    g = gradient(h, A0)\n",
    "    g0 = np.zeros((D, d, D))\n",
    "    \n",
    "    A = A0\n",
    "    \n",
    "    while not np.allclose(g, g0, rtol):\n",
    "        # do a step\n",
    "        A = A - eps * g\n",
    "        \n",
    "        # calculate new gradient\n",
    "        g = gradient(h, A)\n",
    "        \n",
    "        # TODO max iteration protection?\n",
    "    \n",
    "    # calculate ground state energy\n",
    "    E = expVal2Uniform(h, A)\n",
    "    \n",
    "    return E, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groundStateMinimise(h, D, A0=None, rtol=1e-3):\n",
    "    \"\"\"\n",
    "    Find the ground state using gradient descent.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        h : np.array (d, d, d, d)\n",
    "            Hamiltonian to minimise,\n",
    "            ordered topLeft-topRight-bottomLeft-bottomRight.\n",
    "        D : int\n",
    "            Bond dimension\n",
    "        A0 : np.array (D, d, D)\n",
    "            MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right,\n",
    "            initial guess.\n",
    "        rtol : float\n",
    "            Relative convergence criterium.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        E : float\n",
    "            expectation value @ minimum\n",
    "        A : np.array(D, d, D)\n",
    "            ground state MPS,\n",
    "            ordered left-mid-right.\n",
    "    \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
